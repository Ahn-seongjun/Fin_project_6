{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리 순서\n",
    "1. 데이터 피처 확인\n",
    "2. 결측치 처리\n",
    "3. 라벨링으로 문자열 데이터 처리\n",
    "4. 이상치 데이터 처리\n",
    "5. 숫자열 데이터 시각화\n",
    "6. StandardScaler와 로그변환 활용하여 데이터 표준정규화\n",
    "7. EDA 분석(히트맵, 파이차트)\n",
    "8. 남은 문자열 데이터 원핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "rc('font', family=font_name)\n",
    "\n",
    "# Target 값 : price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-00937f620fa6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcar_df_org\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/완성.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcar_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcar_df_org\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcar_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    466\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 468\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1055\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1057\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1058\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2059\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2061\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2062\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2063\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 4, saw 2\n"
     ]
    }
   ],
   "source": [
    "car_df_org = pd.read_csv('data/완성.csv')\n",
    "car_df = car_df_org.copy()\n",
    "car_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 피처 확인\n",
    "\n",
    "- brand : 제조사\n",
    "- name : 차종\n",
    "- type : 연료형태\n",
    "- km : 달린 km 수\n",
    "- year : 제조년도\n",
    "- accident : 사고 여부\n",
    "- color : 색상 (검정색, 회색, 흰색, 기타)\n",
    "- location : 판매 장소\n",
    "- price : 판매 가격\n",
    "- wd : 차 구동방식\n",
    "- trim : 차 트림\n",
    "    - 1 = 기본\n",
    "    - 2 = 조금 좋은 옵션\n",
    "    - 3 = 많이 좋은 옵션\n",
    "    - 4 = 가장 좋은 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 결측치 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('데이터 세트의 Shape:', car_df.shape)\n",
    "print('\\n전체 feature 들의 type \\n',car_df.dtypes.value_counts())\n",
    "\n",
    "# Null 컬럼 확인 : Null이 있는 컬럼과 그 건수를 내림차순으로 출력\n",
    "isnull_series = car_df.isnull().sum()\n",
    "print('\\nNull 컬럼과 그 건수:\\n ', isnull_series[isnull_series > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#불필요한 컬럼 삭제\n",
    "car_df.drop(['location'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['type'] = car_df.apply(lambda x: x['type'].replace('가솔린+LPG','바이퓨얼'), axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문자열 데이터 처리 방식\n",
    "- 라벨링 : accident, wd\n",
    "- 원핫인코딩 : brand, name, type, color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 라벨링으로 문자열 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['accident_e']=0\n",
    "for i in range(0,len(car_df)):\n",
    "        if car_df['accident'][i]=='사고':\n",
    "            car_df['accident_e'][i]=0\n",
    "        elif car_df['accident'][i]=='단순사고(접촉)':\n",
    "            car_df['accident_e'][i]=1\n",
    "        elif car_df['accident'][i]=='단순교환':\n",
    "            car_df['accident_e'][i]=2\n",
    "        else: car_df['accident_e'][i]=3\n",
    "            \n",
    "car_df['wd_e']=0\n",
    "for i in range(0,len(car_df)):\n",
    "        if car_df['wd'][i]=='2WD':\n",
    "            car_df['wd_e'][i]=0\n",
    "        else: car_df['wd_e'][i]=1\n",
    "            \n",
    "car_df['accident'] = car_df['accident_e']\n",
    "car_df['wd'] = car_df['wd_e']\n",
    "car_df['year'] = 2022 - car_df['year']\n",
    "del car_df['accident_e']\n",
    "del car_df['wd_e']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 이상치 데이터 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.drop(car_df.loc[car_df['price']<=100].index, inplace=True)\n",
    "car_df.drop(car_df.loc[car_df['km']>=400000].index, inplace=True)\n",
    "car_df.drop(car_df.loc[car_df['price']>=50000].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 왜곡된 정도 추출 \n",
    "- 모든 변수를 그래프로 확인 할 수 없으므로 \n",
    "    - skew() 함수 사용\n",
    "    - 주의. 숫자형 피처에서 원-핫 인코딩된 카테고리 숫자형 피처 제외\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "# 숫자형 피처에서 원-핫 인코딩된 카테고리 숫자형 피처 제외\n",
    "feautres_index = car_df.dtypes[car_df.dtypes != 'object'].index\n",
    "\n",
    "feautres_index\n",
    "\n",
    "# 왜도 확인\n",
    "skew_features = car_df[feautres_index].apply(lambda x : skew(x))\n",
    "print(skew_features.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 숫자열 데이터 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### km, year, price 변환 전 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('km Histogram')\n",
    "sns.distplot(car_df['km'])\n",
    "#plt.savefig('km Histogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('year Histogram')\n",
    "sns.distplot(car_df['year'])\n",
    "#plt.savefig('year Histogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Sale Price Histogram')\n",
    "sns.distplot(car_df['price'])\n",
    "#plt.savefig('log price Histogram.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터의 분포가 중심에서 왼쪽으로 치우친 형태\n",
    "- 정규 분포에서 벗어나 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. StandardScaler와 로그변환 활용하여 데이터 표준정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### km와 year를 StandardScaler 이용하여 표준화 후 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # StandardScaler 이용 표준화해서 변환\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# car_km_df = car_df[['km','year']]\n",
    "\n",
    "# # StandardScaler 객체 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # fit() : 데이터 변환을 위한 기준 정보 설정\n",
    "# scaler.fit(car_km_df)\n",
    "\n",
    "# # fit() : 설정된 정보를 이용해 데이터 변환\n",
    "# car_scaled = scaler.transform(car_km_df)\n",
    "\n",
    "# # numpy ndarry를 DataFrame으로 변환\n",
    "# car_df_scaled = pd.DataFrame(data=car_scaled, columns=['km','year'])\n",
    "\n",
    "# print('feature 들의 평균 값')\n",
    "# print(car_df_scaled.mean())\n",
    "# print('\\nfeature 들의 분산 값')\n",
    "# print(car_df_scaled.var())\n",
    "\n",
    "# # 모든 컬럼 값의 평균이 0에 가깝고 분산이 1에 가까운 값으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title('km Histogram')\n",
    "# sns.distplot(car_df['km'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 변환 데이터 삽입\n",
    "# car_df[['km','year']] = car_df_scaled[['km','year']]\n",
    "# car_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**타겟값인 Price를 로그변환 후 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과값을 로그 변환하고 다시 분포도 확인\n",
    "plt.title('Log Transformed price Histogram')\n",
    "price = np.log1p(car_df['price'])\n",
    "sns.distplot(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df['price'] = np.log1p(car_df['price']) #로그변환 값으로 타겟값을 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. EDA 분석(히트맵, 파이차트)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,18))\n",
    "\n",
    "corr = car_df.corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.1g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이차트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#brand_per = pd.Series(brand_per['brand'], index=brand_per.index)\n",
    "#brand = ['현대','폭스바겐','제네시스','쌍용','르노삼성','랜드로버','미니포드','쉐보레','BMW','벤츠']\n",
    "\n",
    "brand = car_df_org.groupby('brand')\n",
    "brand_sr = brand.size()\n",
    "brand_sr.plot(kind='pie', figsize=(10,10), autopct= '%1.1f%%', textprops={'size':20})\n",
    "plt.title('brand 분포', size=20)\n",
    "plt.legend(brand_sr.index, loc='best')\n",
    "plt.show()\n",
    "#plt.savefig('brand pi chart.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wd = car_df_org.groupby('wd')\n",
    "wd_sr = wd.size()\n",
    "wd_sr.plot(kind='pie', figsize=(10,10), autopct= '%1.1f%%', textprops={'size':20})\n",
    "plt.title('wd 분포', size=20)\n",
    "plt.legend(wd_sr.index, loc='best')\n",
    "plt.show()\n",
    "#plt.savefig('wd pi chart.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type1 = car_df.groupby('type')\n",
    "type_sr = type1.size()\n",
    "type_sr.plot(kind='pie', figsize=(10,10), autopct= '%1.1f%%', textprops={'size':20})\n",
    "plt.title('type 분포', size=20)\n",
    "plt.legend(type_sr.index, loc='best')\n",
    "plt.show()\n",
    "#plt.savefig('type pi chart.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리 끝난 후 왜도 재확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feautres_index = car_df.dtypes[car_df.dtypes != 'object'].index\n",
    "\n",
    "feautres_index\n",
    "\n",
    "# 왜도 확인\n",
    "skew_features = car_df[feautres_index].apply(lambda x : skew(x))\n",
    "print(skew_features.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 원핫 인코딩으로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('get_dummies() 수행 전 데이터 Shape:', car_df.shape)\n",
    "car_df_ohe = pd.get_dummies(car_df)\n",
    "print('get_dummies() 수행 후 데이터 Shape:', car_df_ohe.shape)\n",
    "car_df_ohe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_df_ohe.to_csv(\"./data/최종 전처리.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
